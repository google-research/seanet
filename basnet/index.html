
<!DOCTYPE html>
<html>
  <head>
    <title>BASNet</title>
    <link
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css"
      rel="stylesheet"
    />
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
    <script src="helper.js" defer></script>
    <style>
      td {
        vertical-align: middle;
        text-align: center;
      }
      audio {
        width: 20vw;
        min-width: 130px;
        max-width: 280px;
      }
      h1, h2, h3, h4, h5, h6, body, b, strong, th {
        color: #595959;
      }
    </style>
  </head>
  <body>
    <div class="container pt-5 mt-5 shadow p-5 mb-5 bg-white rounded">
      <div class="text-center">
        <h1>BASNet</h1><h3>Binaural Angular Separation Network</h3>

        <p class="fst-italic mb-0">
Yang Yang, George Sung, Shao-Fu Shih, Hakan Erdogan, Chehung Lee, Matthias Grundmann
        </p>
        <p><b>Google</b></p>
      </div>
      <p>
        <b>Abstract.</b>
We propose a neural network model that can separate target speech sources from interfering sources at different angular regions using two microphones. The model is trained with simulated room impulse responses (RIRs) using omni-directional microphones without needing to collect real RIRs. By relying on specific angular regions and multiple room simulations, the model utilizes consistent time difference of arrival (TDOA) cues, or what we call delay contrast, to separate target and interference sources while remaining robust in various reverberation environments. We demonstrate the model is not only generalizable to a commercially available device with a slightly different microphone geometry, but also outperforms our previous work which uses one additional microphone on the same device. The model runs in real-time on-device and is suitable for low-latency streaming applications such as telephony and video conferencing.
      </p>
    </div>


    <div class="container shadow p-5 mb-5 bg-white rounded">
      <h3>Data Collection<a id="dialogue"/></h3>
      <p class="mb-0">
To showcase the effectiveness of BASNet in spatial separation, we use an off-the-shelf Pixel tablet to record ESTI
speech played back from three directions: 0 degree in front to the device as well as 90/270 degree which are to the left
and right of the device. The recordings are the capture of the two built-in microphones around the front-view camera
with 7cm spacing. The 0 degree recording is then mixed with 90 or 270 degree speech at various offsets to create
overlapped or non-overlapped speech at 0-dB SNR (third column in the table below). The mixed two channel audios are then
passed through a 48kHz-BASNet model to extract only the 0-degree audio from the mixture.
      </p>
    </div>

    <div class="container shadow p-5 mb-5 bg-white rounded">
      <h3>Samples<a id="dialogue"/></h3>
<p>Note that we used a version of BASNet trained with 48kHz audio end-to-end, whereas the paper describes the 16kHz version of BASNet.</p>

      <div class="container pt-3 table-responsive">
        <table
          class="table table-hover"
          id="dialogue-table"
        >
          <thead>
            <tr>
              <th style="text-align: center;">Angle of interference speech</th>
              <th style="text-align: center;">Mixing of target and interference speech</th>
              <th style="text-align: center">Mixed stereo audio</th>
              <th style="text-align: center">48kHz-BASNet output audio
</th>
            </tr>
          </thead>
          <tbody>

<tr><td ">N/A</td><td>no interference speech</td><td><audio controls>
  <source src= "samples/original_0.wav"  type= "audio/mp3"> </source>
</audio>
</td><td><audio controls>
  <source src= "samples/original_0_basnet.wav"  type= "audio/mp3"> </source>
</audio>
</td>
</tr>
<tr>
  <td ">90 degree</td><td>overlapped target and interference of opposite gender</td><td><audio controls>
  <source src= "samples/mixed_overlapped_opposite_gender_speech_90.wav"  type= "audio/mp3"> </source>
</audio>
</td><td><audio controls>
  <source src= "samples/mixed_overlapped_opposite_gender_speech_90_basnet.wav"  type= "audio/mp3"> </source>
</audio>
</td>
</tr>
<tr>
  <td ">90 degree</td><td>overlapped target and interference of the same gender</td><td><audio controls>
  <source src= "samples/mixed_overlapped_same_gender_speech_90.wav"  type= "audio/mp3"> </source>
</audio>
</td><td><audio controls>
  <source src= "samples/mixed_overlapped_same_gender_speech_90_basnet.wav"  type= "audio/mp3"> </source>
</audio>
</td></tr><tr><td ">90 degree</td><td>non-overlapped</td><td><audio controls>
  <source src= "samples/mixed_non_overlapped_90.wav"  type= "audio/mp3"> </source>
</audio>
</td><td><audio controls>
  <source src= "samples/mixed_non_overlapped_90_basnet.wav"  type= "audio/mp3"> </source>
</audio>
</td>
</tr>
<tr>
  <td ">270 degree</td><td>overlapped target and interference of opposite gender</td><td><audio controls>
  <source src= "samples/mixed_overlapped_opposite_gender_speech_270.wav"  type= "audio/mp3"> </source>
</audio>
</td><td><audio controls>
  <source src= "samples/mixed_overlapped_opposite_gender_speech_270_basnet.wav"  type= "audio/mp3"> </source>
</audio>
</td>
</tr>
<tr>
  <td ">270 degree</td><td>overlapped target and interference of the same gender</td><td><audio controls>
  <source src= "samples/mixed_overlapped_same_gender_speech_270.wav"  type= "audio/mp3"> </source>
</audio>
</td><td><audio controls>
  <source src= "samples/mixed_overlapped_same_gender_speech_270_basnet.wav"  type= "audio/mp3"> </source>
</audio>
</td></tr><tr><td ">270 degree</td><td>non-overlapped</td><td><audio controls>
  <source src= "samples/mixed_non_overlapped_270.wav"  type= "audio/mp3"> </source>
</audio>
</td><td><audio controls>
  <source src= "samples/mixed_non_overlapped_270_basnet.wav"  type= "audio/mp3"> </source>
</audio>
</td></tr>

          </tbody>
        </table>
      </div>
    </div>




  </body>
</html>
